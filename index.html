<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Florin Gheorghiu</title>

    <script src="https://code.jquery.com/jquery-3.2.1.js" integrity="sha256-DZAnKJ/6XZ9si04Hgrsxu/8s717jcIzLy3oi35EouyE=" crossorigin="anonymous"></script>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">


    <link href="style.css" type="text/css" rel="stylesheet">


</head>

<body class="container-fluid">

    <div class="row">

        <div id="side" class="col-sm-2">
            <ul class="navy">

                <li class="navy-link"><a id="about" style="color: black" href="#">ABOUT</a></li>

                <li class="navy-link">PROJECTS

                    <ul class="side-category">
                        <li id="games"><a href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">Gamifying biology</span></a></li>
                        <li id="website"><a href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">Front-end adventures</span></a></li>
                        <li id="4th"><a href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">NeuroMovies</span></a></li>
                        <li id="3rd"><a  href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">Eye gaze & storytelling</span></a></li>
                        <li id="hatch"><a href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">Hatch London</span></a></li>
                        <li id="vr"><a href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">No more ghost towns</span></a></li>
                    </ul>
                </li>

            </ul>
        </div>

        <div id="tabula" class="col-sm-10">

            <div class="row">

                <div id="pictures" class="col-sm-6">

                    <div id="pictures-intro">
                        <img src="assets/intro1.jpg" style="margin: 3% 0 0 20% !important; display: inline-flex; width: 55%">
                        <img src="assets/igempresentation.jpg" style="margin: 3% 0 0 20% !important; display: inline-flex; width: 55%">
                        <img src="assets/intro2.jpg" style="margin: 3% 0 0 20% !important; display: inline-flex; width: 55%">
                    </div>
                        <!-- photos for the eye gazing project -->

                    <div id="pictures-3rd" class="row">

                            <img src="assets/project-image-gaze1.jpg" id="project-image-1" class="project-image">
                            <img src="assets/project-image-gaze2.jpg" id="project-image-4" class="project-image">

                    </div>

                    <!-- photos for the biology games -->

                    <div id="pictures-games">

                        <iframe class="museumvideo" src="https://player.vimeo.com/video/243147845" width="460" height="280" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
                        <img src="assets/ScienceMuseum1.jpg" id="project-image-5" class="project-image" style="height:10% !important; width: 40% !important; margin-left: 5%">
                        <img src="assets/project-image-sm2.jpg" id="project-image-6" class="project-image" style="height:10% !important; width: 40% !important;">
                        <img src="assets/game.jpg" id="project-image-7" class="project-image" style="height:40% !important; width: 80% !important;">

                        <iframe class="museumvideo" src="https://player.vimeo.com/video/245205558" width="460" height="280" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
                        <img src="assets/padbuilding.jpg" class="project-image" style="height:40% !important; width: 80% !important; margin: 10% 0 0 10%">
                    </div>

                    <!-- photos for the ML -->
                    <div id="pictures-4th">
                        <img src="assets/NeuMovies.jpg"class="project-image" height="10%" width="80%">
                        <img src="assets/neumovies1.jpg" class="project-image neu-images" height="10%" width="90%">
                        <img src="assets/neumovies2.jpg" class="project-image neu-images" height="10%" width="90%">
                    </div>

                    <!-- photos for the website -->
                    <div id="pictures-website">

                            <img src="assets/website1.jpg" class="project-image" height="10%" width="80%" style="margin: 3% 0 0 5% !important">
                            <img src="assets/website2.jpg" class="project-image" height="10%" width="80%" style="margin: 3% 0 0 5% !important">
                            <img src="assets/website3.jpg" class="project-image" height="10%" width="80%" style="margin: 3% 0 0 5% !important">

                            <img src="assets/UserJourneyoverview.png" class="project-image" height="10%" width="80%" style="margin: 20% 0 30% 15% !important">
                            <img src="assets/UserJourney-Part1.png" class="project-image" height="10%" width="80%" style="margin: 10% 0 10% 10% !important">
                            <img src="assets/barchitecture.png" class="project-image" height="10%" width="80%" style="margin: 3% 0 0 10% !important">
                    </div>

                    <!-- photos for Hatch-->
                    <div id="pictures-hatch">
                        <img src="assets/hatch.jpg" id="project-image-14" class="project-image" height="10%" width="80%" style="margin: 20% 0 20% 10%">
                    </div>

                </div>

                <!-- The column with the text in -->
                <div id="descriptions" class="col-sm-6">

                    <div id="introbit">
                        <p style="font-size: 3vw" class="intro">Florin Gheorghiu</p>

                        <p style="padding-top: 1%" class="intro">London,UK</p>

                        <p class="intro"><b>Officially</b>, I spend my time reading about neurons & AI, designing experiments and doing multivariate stats at UCL.</p>

                        <p class="intro"><b>Unofficially</b>, I code games and websites, talk about synthetic biology, play with Arduinos and think about how technology can completely change the way we interact with the world around us.</p>

                        <p class="intro">Here's my CV for education and other activities, such as tutoring experience and international development.</p>

                        <div id="contacts">
                            <a href="mailto:florin.gheorghiu24@gmail.com" target="_top"><svg width="7.5%" height="7.5%" viewBox="0 0 14 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                                <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                                <title>mail</title>
                                <desc>Created with Sketch.</desc>
                                <defs></defs>
                                <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                    <g id="mail" fill="#000000">
                                        <path d="M0,4 L0,12 C0,12.55 0.45,13 1,13 L13,13 C13.55,13 14,12.55 14,12 L14,4 C14,3.45 13.55,3 13,3 L1,3 C0.45,3 0,3.45 0,4 L0,4 Z M13,4 L7,9 L1,4 L13,4 L13,4 Z M1,5.5 L5,8.5 L1,11.5 L1,5.5 L1,5.5 Z M2,12 L5.5,9 L7,10.5 L8.5,9 L12,12 L2,12 L2,12 Z M13,11.5 L9,8.5 L13,5.5 L13,11.5 L13,11.5 Z" id="Shape"></path>
                                    </g>
                                </g>
                            </svg></a>
                            <a href="https://github.com/darksipu"><svg width="7.5%" height="5.5%" viewBox="0 0 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                                <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                                <title>mark-github</title>
                                <desc>Created with Sketch.</desc>
                                <defs></defs>
                                <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                    <g id="mark-github" fill="#000000">
                                        <path d="M8,0 C3.58,0 0,3.58 0,8 C0,11.54 2.29,14.53 5.47,15.59 C5.87,15.66 6.02,15.42 6.02,15.21 C6.02,15.02 6.01,14.39 6.01,13.72 C4,14.09 3.48,13.23 3.32,12.78 C3.23,12.55 2.84,11.84 2.5,11.65 C2.22,11.5 1.82,11.13 2.49,11.12 C3.12,11.11 3.57,11.7 3.72,11.94 C4.44,13.15 5.59,12.81 6.05,12.6 C6.12,12.08 6.33,11.73 6.56,11.53 C4.78,11.33 2.92,10.64 2.92,7.58 C2.92,6.71 3.23,5.99 3.74,5.43 C3.66,5.23 3.38,4.41 3.82,3.31 C3.82,3.31 4.49,3.1 6.02,4.13 C6.66,3.95 7.34,3.86 8.02,3.86 C8.7,3.86 9.38,3.95 10.02,4.13 C11.55,3.09 12.22,3.31 12.22,3.31 C12.66,4.41 12.38,5.23 12.3,5.43 C12.81,5.99 13.12,6.7 13.12,7.58 C13.12,10.65 11.25,11.33 9.47,11.53 C9.76,11.78 10.01,12.26 10.01,13.01 C10.01,14.08 10,14.94 10,15.21 C10,15.42 10.15,15.67 10.55,15.59 C13.71,14.53 16,11.53 16,8 C16,3.58 12.42,0 8,0 L8,0 Z" id="Shape"></path>
                                    </g>
                                </g>
                            </svg></a>
                        </div>

                    </div>

                    <div id="descriptions-website" class="description-container">

                        <p id="description-website1" class="descriptions">I designed the UX and coded UCL 2017’s iGEM <a style="text-decoration: none" href="http://2017.igem.org/Team:UCL">website</a>. It was my first long-term major project, throughout which I learnt and practiced a lot of HTML, CSS and Javascript. Unfortunately, the vanilla in web development, but looking forward to playing around with React soon. </p>

                        <p id="description-website3" class="descriptions">Throughout the project, I thought about finding easy solutions to saying something clearly and making it easy to consume the information on our wiki. As a newbie, I didn’t use any professional software for the UX, but went for something quick and practical to get everyone in the team an idea of what content needs producing (i.e. text and diagrams). I worked closely with the other 8 team members to achieve this, reiterating on the designs after their feedback.</p>

                        <p id="description-website2" class="descriptions">Special thanks to Anima Sutradhar for the diagrams and artwork, and together with Rabia T Khan and Jaime Domingues from Benevolent AI for help, advice and suggestions on the UX.</p>


                        <p id="description-website4" class="descriptions">The whole website took around 3 months from the first ideas, to wireframes, initial designs, agreeing on a structure and theme with the team, creating content, refining, testing UX and dealing with iGEM’s ridiculous rules about website hosting.</p>

                        <p id="description-website5" class="descriptions">From the start, I wanted to build a website that wasn’t just pretty, but one that satisfied the purpose of our project: serve as a wiki for people to build upon it, access information and have a pleasant reading experience. </p>

                        <p id="description-website6" class="descriptions">Also, given the limitations with iGEM website hosting, I decided to use vanilla HTML, CSS and JavaScript. However, along the way, the most interesting part was the challenge of designing good UX.</p>

                        <p id="description-website7" class="descriptions">Here are some of the wireframes for the home and project description pages. It was a lengthy process of design, going back and forth between the person who was designing the diagrams and visuals, what the die-hard biologists wanted to put on the first page and myself. However, I felt like it helped me come up with alternative solutions and understand why some parts of the project were important.</p>

                        <p id="description-website8" class="descriptions">I did not use any professional tools for UX, relying on a way to prototype quickly and practically, while getting everyone in the team on the same page in terms of what content needs to be produced.</p>

                        <p id="description-website9" class="descriptions">My first web development gig  helped me build the necessary tools to deploy a website, undertake a lengthy process with specific deliverables and work towards satisfying my ‘clients’ (as I like to call the iGEM judges and my team mates). </p>

                        <p id="description-website10" class="descriptions">The skills proved useful, as recently I used them in a hackathon (see <i>Hatch London</i>) to build a prototype for an online platform.</p>

                        <button id="button-website1" type="button" class="btn btn-dark btns">Scope</button>
                        <button id="button-website2" type="button" class="btn btn-dark btns">Process</button>
                        <button id="button-website3" type="button" class="btn btn-dark btns">Moving forward</button>

                    </div>

                    <div id="descriptions-games" class="description-container">

                        <p id="description-games1" class="descriptions">During my iGEM project, I was curious how games can be used to tell a story about synthetic biology and enhance science communication.</p>
                        <p id="description-games2" class="descriptions">I had 1 month to build an installation that would impress the <a style="text-decoration: none" href="https://www.sciencemuseum.org.uk/see-and-do/lates">London Science Museum Lates</a> team enough to be part of their evening. After a few iterations, I decided to design and make from scratch 2 games to gamify the central dogma of molecular biology. The idea was well received and now I’m working on the feedback to improve the application of games in science communication.</p>
                        <p id="description-games3" class="descriptions">All the whys and hows are below. <a style="text-decoration: none" href="https://github.com/darksipu/cell-games">Here</a>’s the code on GitHub to play yourself and build on top of it (details there).</p>

                        <p id="description-games4" class="descriptions">I approached the project like a psychology experiment, testing whether through an installation we can give an intuitive understanding of a molecular biology concept, get people excited and transform the experience of gaming from and isolated bedroom nerd to a social game that you’d play around the Christmas table. My hypothesis was that such a combination would be well received and replaced the usual experimental controls with user testing.</p>
                        <p id="description-games5" class="descriptions">But arcade games are still so fun. So, I tried to design something that has the fun of traditional video games, adds a social component and is a useful gateway into synthetic biology.</p>
                        <p id="description-games6" class="descriptions">Also, I wanted to couple my newly learnt molecular biology with something that had wanted to do for a while: hardware.</p>


                        <p id="description-games7" class="descriptions">Initially, I got inspired by work that I did in my 3rd year thesis: breaking the 4th wall in media experience. I decided that the game should make users part of the mechanisms involved in the scientific concept explained. So, my first idea was of a live <a style="text-decoration: none;" href="https://en.wikipedia.org/wiki/Quorum_sensing">quorum sensing</a> exercise: through a web app that uses geolocation, people can use their phones to move around London, come together and produce phenotypes, similarly to how bacteria do it. The phenotypes could be shown on a map, or using augmented reality to place virtual objects around London.</p>
                        <p id="description-games8" class="descriptions">However, there was a constraint of space at the London Science Museum, so the idea shifted to using some sensors for proximity. Still, with one month on hand, I pivoted completely to gamify the central dogma of molecular biology. This way, I could finish the actual installation and explain a fundamental idea in molecular biology, which if understood, would also help a user understand what the latest article about bacteria and their DNA actually means.</p>
                        <p id="description-games9" class="descriptions">After settling on the central dogma, I took its two central mechanisms in bacteria: transcription and translation. I thought of pairing up transcription with a Dance Dance Revolution-like game and translation with a classic arcade game. The fun was there and so was the part about illustrating principles. To add the last component about making players interact, the two games had to be connected: the results from the translation game would feed into the transcription one, with participants having to see what each other is doing.</p>

                        <p id="description-games10" class="descriptions">On September 27th, the two games were ready, but making one feed into another was not ready yet, even after a week of user testing. The solution was to have people play in pairs, supplementing the experience by engaging with the players before and after the game to explain the connection between translation and transcription.</p>
                        <p id="description-games11" class="descriptions">A school teacher invited us to take the installation to a local school in London and I got user feedback throughout the night about gameplay and the potential of gamification in science communication. I was particularly interested in seeing what their feedback was on learning something about biology, the social component and whether they would take interest in the topic in the near future. </p>
                        <p id="description-games12" class="descriptions">Overall, I learnt a lot about object-oriented programming, became comfortable with building physical objects and with finding solutions to unexpected issues (e.g. when building the dance pad). Importantly, now I know how to start approaching an iterative process of design, when to test with users and how to strike a balance between functionality and pretty design.</p>
                        <p id="description-games13" class="descriptions">My next plan with Cell Games is to first implement the feedback from the event and connect the 2 games via an express server, so shoot me an email if you’d like to collaborate! In the near future, I’d want to explore the live quorum sensing exercise and start prototyping.</p>

                        <button id="button-games1" type="button" class="btn btn-dark btns">Scope</button>
                        <button id="button-games2" type="button" class="btn btn-dark btns">Process</button>
                        <button id="button-games3" type="button" class="btn btn-dark btns">Moving forward</button>
                    </div>

                    <div id="descriptions-3rd" class="description-container">

                        <p class="descriptions">I think a lot about how we experience and perceive the world around us. So, the concept of breaking the 4th wall in theatre appealed to me and wanted to test it in cognitive science. My 3rd year project focused on using narratives and eye-tracking to see whether eye gaze and storytelling have a common thread to explore.</p>

                        <p class="descriptions">The experiment manipulated the storyteller’s gaze, self-referencing through language and whether the person believed that they were seen or not by the storyteller. I started from theories of self-referencing and direct eye gaze perception and chose to look at the levels of immersion into the narrative and overt attention allocation.</p>

                        <p class="descriptions">Gaze direction and the belief of being seen turned out to influence narrative immersion and attention allocation. Now, I plan to continue this exploration in the design of storytelling experiences that leverage these effects. <a style="text-decoration: none" href="assets/FlorinGheorghiuDissertation.pdf" download>Here</a> you can download the dissertation.</p>

                        <p class="descriptions">Both technology and storytelling are designed to immerse us into their microworlds. To design  and implement technology that helps us immerse ourselves into the surrounding world and be present, I thought exploring factors related to storytelling and that may have a biological underlying effect is worthwhile.</p>
                        <p class="descriptions">When researching, eye gaze and particularly direct eye gaze came up again and again with ‘special’ effects on cognition. Looking through studies that measured EDA, heart rate, EEG and behavioural effects, it became clear that it’s a factor that can influence storytelling. Combined with theories of self-referencing, that suggest that memory is augmented when the individual processes stimuli in relation to the self, I designed the task to manipulate all of these factors, while considering how the 4th wall of cognitive science can be broken.</p>
                        <p class="descriptions">Another idea is how we combine thi idea of breaking the 4th wall through augmented emotional experiences such as the sublime.</p>

                        <p class="descriptions">I used two stories from the acclaimed text-based RPG. Throughout the process, I had to become an actor, lighting and camera expert and learn about eye-tracking.</p>
                        <p class="descriptions">The task wasn’t easy and using a new open-source eye-tracker resulted in having to through away quite a lot of data-points.</p>

                        <p class="descriptions">My end aim with this line of ideas is to integrate it with the design of stories that leverage these effects. If direct eye gaze does indeed enhance self-referential processing and enhances memory, I would like to use machine-learning based approaches, coupled with automated animation processes to design experiences that enhance self-referential processing right before key information is to be remembered. Is that a way to make someone more present into the current moment? Some would disagree, but I’m sure it’s a worthwhile idea.</p>
                        <p class="descriptions">This paper really attracted my attention to how machine learning could be combined with the outcomes of this research. Also, thinking about the idea of believing that you’re interacting with some faceless technology, a general intelligence AI is soon coming. Leaving the problem of consciousness aside, how would someone interact with such an entity. Some of ideas might prove relevant.</p>

                        <button id="button-3rd1" type="button" class="btn btn-dark btns">Scope</button>
                        <button id="button-3rd2" type="button" class="btn btn-dark btns">Process</button>
                        <button id="button-3rd3" type="button" class="btn btn-dark btns">Moving forward</button>

                    </div>

                    <div id="descriptions-4th" class="description-container">

                        <p id="description-4th1" class="descriptions">I’m currently part of the LAB lab at UCL. I joined to grasp the idea of network interaction in the brain, as it seems like the way forward to understand the brain in real life contexts.</p>
                        <p id="description-4th2" class="descriptions">Before starting to scan, I have been working on using the Google Cloud Speech API to align subtitles from a movie with the audio description for the blind (DVS service). I made a script that uses Voice Activity Detection (VAD) in Python to get wav files of segments of speech, turn them into flac format, send them to Google and get back a json with speech onset timing and the content. Due to pauses in speech, I am working on using text similarity to combine parts of sentences that were split during the VAD.</p>
                        <p id="description-4th3" class="descriptions">Read further to see where I see this going both in terms of programming and the neuroscience.</p>

                        <div class="githubs">
                           <a href="https://github.com/jskipper/movie"><svg width="10%" height="10%" viewBox="0 0 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                                <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                                <title>mark-github</title>
                                <desc>Created with Sketch.</desc>
                                <defs></defs>
                                <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                    <g id="mark-github" fill="#000000">
                                        <path d="M8,0 C3.58,0 0,3.58 0,8 C0,11.54 2.29,14.53 5.47,15.59 C5.87,15.66 6.02,15.42 6.02,15.21 C6.02,15.02 6.01,14.39 6.01,13.72 C4,14.09 3.48,13.23 3.32,12.78 C3.23,12.55 2.84,11.84 2.5,11.65 C2.22,11.5 1.82,11.13 2.49,11.12 C3.12,11.11 3.57,11.7 3.72,11.94 C4.44,13.15 5.59,12.81 6.05,12.6 C6.12,12.08 6.33,11.73 6.56,11.53 C4.78,11.33 2.92,10.64 2.92,7.58 C2.92,6.71 3.23,5.99 3.74,5.43 C3.66,5.23 3.38,4.41 3.82,3.31 C3.82,3.31 4.49,3.1 6.02,4.13 C6.66,3.95 7.34,3.86 8.02,3.86 C8.7,3.86 9.38,3.95 10.02,4.13 C11.55,3.09 12.22,3.31 12.22,3.31 C12.66,4.41 12.38,5.23 12.3,5.43 C12.81,5.99 13.12,6.7 13.12,7.58 C13.12,10.65 11.25,11.33 9.47,11.53 C9.76,11.78 10.01,12.26 10.01,13.01 C10.01,14.08 10,14.94 10,15.21 C10,15.42 10.15,15.67 10.55,15.59 C13.71,14.53 16,11.53 16,8 C16,3.58 12.42,0 8,0 L8,0 Z" id="Shape"></path>
                                    </g>
                                </g>
                            </svg></a>
                        </div>


                        <p id="description-4th4" class="descriptions">My goal is to take the brain outside the lab and I saw working on network interaction as a great chance of understanding a higher-level functioning of cognitive processes. At the moment, I am spending time understanding what conclusions we can draw from fMRI data and think about the questions that we can answer through an average signal across the neurons in a voxel.</p>

                        <p id="description-4th5" class="descriptions">A side consequence that became a big part of the project is the decoding of movies. For this, I am using the transcribed audio descriptions for the blind, currently building a LSTM network to train it on Deep Mind’s Kinetics <a style="text-decoration: none" href="https://deepmind.com/research/open-source/open-source-datasets/kinetics/">data</a> and using NLP to mine commentaries about scenes in the movies. This leads to quite a narrow focus of the decoding, specific to the movie.</p>

                        <p class="descriptions">One aspect of it that I am exploring is linking the physiology to the computational aspect more thoroughly.</p>


                        <p class="descriptions">My first aim is to finish off a Python script that allows me to query all the information that we have about a movie at specific time periods. I am planning on approaching the analysis in 2 ways: starting from the brain and starting from the stimulus.</p>

                        <p class="descriptions">From the brain side, if we observe an interaction between networks at specific time points, I want to query my movie about what stimulus triggered that BOLD signal. So, I would get the time period, then use the RNN to classify the action happened in this short clip, extract information from the audio description of the same time, classify objects with Tensorflow’s Inception model and if available get a summary of the scene commentary. Obviously, there are multiple resolutions to play around with and this is something that I am looking forward to once we finish scanning.</p>

                        <p class="descriptions">From the stimulus side, I am interested to see if having the same type of stimulus appear across different time points across the movie would result in the same network interaction in the brain. For this, we would go the other way around, also comparing to what the literature says about stimuli triggering the activation of specific brain regions (e.g. angry faces for the amygdala).</p>

                        <p class="descriptions">The next steps for me, at least, is to integrate this knowledge into the design of interfaces and experiences. While some might think of an evil application to get people hooked on Netflix movies designed to leverage what we know about the brain, they can already do this without all of this data.</p>

                        <p class="descriptions">It also relates to how we can create a super AI, to which I’m thinking that a deep neural network could be trained based on the brain data and the stimuli presented in the movies to produce what time of stimulus produces what kind of activation.</p>

                        <button id="button-4th1" type="button" class="btn btn-dark btns">Scope</button>
                        <button id="button-4th2" type="button" class="btn btn-dark btns">Process</button>
                        <button id="button-4th3" type="button" class="btn btn-dark btns">Moving forward</button>
                    </div>

                    <div id="descriptions-hatch" class="description-container">

                        <p id="description-hatch1" class="descriptions">Hatch London was a hackathon aimed at solving issues coming from the UN. On the day, to my surprise, we were allocated a project to decrease gender discrimination and sexual harassment and assault.</p>
                        <p id="description-hatch2" class="descriptions">I was one of the 2 coders in a team of 5, putting forward the idea of creating an online platform through which agents that implement interventions to reduce sexual harassment can use to assess their effectiveness and improve their implementation strategy. My experience in international development with EPAfrica (see Resume) inspired me to think about how effective these are.</p>
                        <p id="description-hatch3" class="descriptions">Our prototype took data regarding sexual assaults and plotted them on a map. I worked on getting the Geolocation function of the Maps API to work with the UK Police API.</p>

                        <div class="githubs">
                            <a href="https://github.com/wonjoonSeol/hatch-template-project"><svg width="15%" height="10%" viewBox="0 0 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                                <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                                <title>mark-github</title>
                                <desc>Created with Sketch.</desc>
                                <defs></defs>
                                <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                    <g id="mark-github" fill="#000000">
                                        <path d="M8,0 C3.58,0 0,3.58 0,8 C0,11.54 2.29,14.53 5.47,15.59 C5.87,15.66 6.02,15.42 6.02,15.21 C6.02,15.02 6.01,14.39 6.01,13.72 C4,14.09 3.48,13.23 3.32,12.78 C3.23,12.55 2.84,11.84 2.5,11.65 C2.22,11.5 1.82,11.13 2.49,11.12 C3.12,11.11 3.57,11.7 3.72,11.94 C4.44,13.15 5.59,12.81 6.05,12.6 C6.12,12.08 6.33,11.73 6.56,11.53 C4.78,11.33 2.92,10.64 2.92,7.58 C2.92,6.71 3.23,5.99 3.74,5.43 C3.66,5.23 3.38,4.41 3.82,3.31 C3.82,3.31 4.49,3.1 6.02,4.13 C6.66,3.95 7.34,3.86 8.02,3.86 C8.7,3.86 9.38,3.95 10.02,4.13 C11.55,3.09 12.22,3.31 12.22,3.31 C12.66,4.41 12.38,5.23 12.3,5.43 C12.81,5.99 13.12,6.7 13.12,7.58 C13.12,10.65 11.25,11.33 9.47,11.53 C9.76,11.78 10.01,12.26 10.01,13.01 C10.01,14.08 10,14.94 10,15.21 C10,15.42 10.15,15.67 10.55,15.59 C13.71,14.53 16,11.53 16,8 C16,3.58 12.42,0 8,0 L8,0 Z" id="Shape"></path>
                                    </g>
                                </g>
                            </svg></a>
                        </div>

                    </div>

                </div>

            </div>

        </div>

    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js" integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn" crossorigin="anonymous"></script>
    <script language="javascript" type="text/javascript" src="actions.js"></script>
</body>

</html>
