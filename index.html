<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Florin Gheorghiu</title>

    <script src="https://code.jquery.com/jquery-3.2.1.js" integrity="sha256-DZAnKJ/6XZ9si04Hgrsxu/8s717jcIzLy3oi35EouyE=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js" integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="assets/modules/octicons/lib/octicons.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">


    <link href="style.css" type="text/css" rel="stylesheet">
    <script language="javascript" type="text/javascript" src="actions.js"></script>
    
</head>

<body class="container-fluid">

    <div class="row">

        <div id="side" class="col-sm-2">
            <ul class="navy">

                <li class="navy-link"><a id="about" style="color: black" href="#">ABOUT</a></li>

                <li class="navy-link">PROJECTS

                    <ul class="side-category">
                        <li id="games"><a href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">Gamifying biology</span></a></li>
                        <li id="website"><a href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">Front-end adventures</span></a></li>
                        <li id="4th"><a href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">NeuroMovies</span></a></li>
                        <li id="3rd"><a  href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">Eye gaze & storytelling</span></a></li>
                        <li id="hatch"><a href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">Hatch London</span></a></li>
                        <li id="vr"><a href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">Virtual Reality</span></a></li>
                    </ul>
                </li>

            </ul>
        </div>

        <div id="tabula" class="col-sm-10">

            <div class="row">

                <div id="pictures" class="col-sm-6">

                    <div id="pictures-intro">
                        <img src="assets/intro1.jpg" style="margin: 3% 0 0 20% !important; display: inline-flex; width: 55%">
                        <img src="assets/igempresentation.jpg" style="margin: 3% 0 0 20% !important; display: inline-flex; width: 55%">
                        <img src="assets/intro2.jpg" style="margin: 3% 0 0 20% !important; display: inline-flex; width: 55%">
                    </div>
                        <!-- photos for the eye gazing project -->

                    <div id="pictures-3rd" class="row">

                            <img src="assets/project-image-gaze1.jpg" id="project-image-1" class="project-image">
                            <img src="assets/project-image-gaze2.jpg" id="project-image-4" class="project-image">

                    </div>

                    <!-- photos for the biology games -->

                    <div id="pictures-games">
                        <iframe id="museumvideo" src="https://player.vimeo.com/video/243147845" width="460" height="280" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
                        <img src="assets/ScienceMuseum1.jpg" id="project-image-5" class="project-image" style="height:10% !important; width: 40% !important; margin-left: 5%">
                        <img src="assets/project-image-sm2.jpg" id="project-image-6" class="project-image" style="height:10% !important; width: 40% !important;">
                        <img src="assets/game.jpg" id="project-image-7" class="project-image" style="height:40% !important; width: 80% !important;">

                    </div>

                    <!-- photos for the ML -->
                    <div id="pictures-4th">
                        <img src="assets/NeuMovies.jpg" id="project-image-9" class="project-image" height="10%" width="80%">
                    </div>

                    <!-- photos for the website -->
                    <div id="pictures-website">

                            <img src="assets/website1.jpg" class="project-image" height="10%" width="80%" style="margin: 3% 0 0 5% !important">
                            <img src="assets/website2.jpg" class="project-image" height="10%" width="80%" style="margin: 3% 0 0 5% !important">
                            <img src="assets/website3.jpg" class="project-image" height="10%" width="80%" style="margin: 3% 0 0 5% !important">

                            <img src="assets/UserJourneyoverview.png" class="project-image" height="10%" width="80%" style="margin: 20% 0 30% 15% !important">
                            <img src="assets/UserJourney-Part1.png" class="project-image" height="10%" width="80%" style="margin: 10% 0 10% 10% !important">
                            <img src="assets/barchitecture.png" class="project-image" height="10%" width="80%" style="margin: 3% 0 0 10% !important">
                    </div>

                    <!-- photos for Hatch-->
                    <div id="pictures-hatch">
                        <img src="assets/ScienceMuseum1.jpg" id="project-image-14" class="project-image" height="10%" width="80%">
                        <img src="assets/ScienceMuseum1.jpg" id="project-image-15" class="project-image" height="10%" width="80%">
                    </div>

                </div>

                <!-- The column with the text in -->
                <div id="descriptions" class="col-sm-6">

                    <div id="introbit">
                        <p style="font-size: 3vw" class="intro">Florin Gheorghiu</p>

                        <p style="padding-top: 1%" class="intro">London,UK</p>

                        <p class="intro"><b>Officially</b>, I spend my time reading about neurons, designing experiments and doing multivariate stats at UCL.</p>

                        <p class="intro"><b>Unofficially</b>, I code games and websites, think about users, play with Arduinos and talk about synthetic biology.</p>

                        <p class="intro">Here's my CV for education and other activities, such as tutoring experience and international development.</p>

                        <div id="contacts">
                            <a href="mailto:florin.gheorghiu24@gmail.com" target="_top"><svg width="7.5%" height="7.5%" viewBox="0 0 14 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                                <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                                <title>mail</title>
                                <desc>Created with Sketch.</desc>
                                <defs></defs>
                                <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                    <g id="mail" fill="#000000">
                                        <path d="M0,4 L0,12 C0,12.55 0.45,13 1,13 L13,13 C13.55,13 14,12.55 14,12 L14,4 C14,3.45 13.55,3 13,3 L1,3 C0.45,3 0,3.45 0,4 L0,4 Z M13,4 L7,9 L1,4 L13,4 L13,4 Z M1,5.5 L5,8.5 L1,11.5 L1,5.5 L1,5.5 Z M2,12 L5.5,9 L7,10.5 L8.5,9 L12,12 L2,12 L2,12 Z M13,11.5 L9,8.5 L13,5.5 L13,11.5 L13,11.5 Z" id="Shape"></path>
                                    </g>
                                </g>
                            </svg></a>
                            <a href="https://github.com/darksipu"><svg width="7.5%" height="5.5%" viewBox="0 0 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                                <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                                <title>mark-github</title>
                                <desc>Created with Sketch.</desc>
                                <defs></defs>
                                <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                    <g id="mark-github" fill="#000000">
                                        <path d="M8,0 C3.58,0 0,3.58 0,8 C0,11.54 2.29,14.53 5.47,15.59 C5.87,15.66 6.02,15.42 6.02,15.21 C6.02,15.02 6.01,14.39 6.01,13.72 C4,14.09 3.48,13.23 3.32,12.78 C3.23,12.55 2.84,11.84 2.5,11.65 C2.22,11.5 1.82,11.13 2.49,11.12 C3.12,11.11 3.57,11.7 3.72,11.94 C4.44,13.15 5.59,12.81 6.05,12.6 C6.12,12.08 6.33,11.73 6.56,11.53 C4.78,11.33 2.92,10.64 2.92,7.58 C2.92,6.71 3.23,5.99 3.74,5.43 C3.66,5.23 3.38,4.41 3.82,3.31 C3.82,3.31 4.49,3.1 6.02,4.13 C6.66,3.95 7.34,3.86 8.02,3.86 C8.7,3.86 9.38,3.95 10.02,4.13 C11.55,3.09 12.22,3.31 12.22,3.31 C12.66,4.41 12.38,5.23 12.3,5.43 C12.81,5.99 13.12,6.7 13.12,7.58 C13.12,10.65 11.25,11.33 9.47,11.53 C9.76,11.78 10.01,12.26 10.01,13.01 C10.01,14.08 10,14.94 10,15.21 C10,15.42 10.15,15.67 10.55,15.59 C13.71,14.53 16,11.53 16,8 C16,3.58 12.42,0 8,0 L8,0 Z" id="Shape"></path>
                                    </g>
                                </g>
                            </svg></a>
                        </div>

                    </div>

                    <div id="descriptions-website" class="description-container">

                        <p id="description-website1" class="descriptions">I designed the UX and coded the UCL 2017’s iGEM <a style="text-decoration: none" href="http://2017.igem.org/Team:UCL">website</a>. Vanilla HTML, CSS with Bootstrap and JS. Looking forward to using React for the next project.</p>

                        <p id="description-website2" class="descriptions">Special thanks to Anima Sutradhar for the diagrams and artwork, and together with Rabia T Khan and Jaime Domingues for help, advice and suggestions on the UX.</p>

                        <p id="description-website3" class="descriptions">You can download some of the wireframes that I made when designing the UX. As a newbie to it, I didn't use any professional software, but went for something quick and practical and would get everyone in the team an idea of what content needs producing.</p>

                        <p id="description-website4" class="descriptions">The whole website took around 3 months from the first ideas, to wireframes, initial designs, agreeing on a structure and theme with the team, creating content, refining, testing UX and dealing with iGEM’s ridiculous rules about website hosting.</p>

                        <p id="description-website5" class="descriptions">From the start, I wanted to build a website that wasn’t just pretty, but one that satisfied the purpose of our project: serve as a wiki for people to build upon it, access information and have a pleasant reading experience. </p>

                        <p id="description-website6" class="descriptions">Also, given the limitations with iGEM website hosting, I decided to use vanilla HTML, CSS and JavaScript. However, along the way, the most interesting part was the challenge of designing good UX.</p>

                        <p id="description-website7" class="descriptions">Here are some of the wireframes for the home and project description pages. It was a lengthy process of design, going back and forth between the person who was designing the diagrams and visuals, what the die-hard biologists wanted to put on the first page and myself. However, I felt like it helped me come up with alternative solutions and understand why some parts of the project were important.</p>

                        <p id="description-website8" class="descriptions">I did not use any professional tools for UX, relying on a way to prototype quickly and practically, while getting everyone in the team on the same page in terms of what content needs to be produced.</p>

                        <p id="description-website9" class="descriptions">My first web development gig  helped me build the necessary tools to deploy a website, undertake a lengthy process with specific deliverables and work towards satisfying my‘clients’ (as I call the iGEM judges and my team mates). </p>

                        <p id="description-website10" class="descriptions">The skills proved useful, as recently I used them in a hackathon (see the Hatch London page) to build a prototype for an online platform.</p>

                        <button id="button-website1" type="button" class="btn btn-dark btns">Scope</button>
                        <button id="button-website2" type="button" class="btn btn-dark btns">Process</button>
                        <button id="button-website3" type="button" class="btn btn-dark btns">Moving forward</button>

                    </div>

                    <div id="descriptions-games" class="description-container">

                        <p id="description-games1" class="descriptions">During my iGEM project, I was curious how games can be used to tell a story about synthetic biology and enhance science communication.</p>
                        <p id="description-games2" class="descriptions">I had 1 month to build an installation that would impress the London Science Museum Lates team enough to be part of their evening. After a few sketches, I decided to design and make from scratch 2 games to gamify the central dogma of molecular biology. After all the fun, I turned the project into an iterative process, which I am still working on now to develop.</p>
                        <p id="description-games3" class="descriptions">To read about the process and all the whys, click below. <a style="text-decoration: none" href="https://github.com/darksipu/cell-games">Here</a>’s the GitHub to build your own.</p>

                        <p id="description-games4" class="descriptions">I started with 3 ideas for the installation: give an intuitive understanding of the concept, get people excited about the idea and also transform the experience of gaming from an isolated bedroom nerd to resembling games that you’d play around the Christmas table. My hypothesis was that such a combination would be well received.</p>
                        <p id="description-games5" class="descriptions">But arcade games are still so fun. So, I tried to design something that has the fun of traditional video games, adds a social component and is a useful gateway into synthetic biology.</p>
                        <p id="description-games6" class="descriptions">Also, I wanted to couple my newly learnt molecular biology with something that had wanted to do for a while: hardware. While at the time I was comfortable with writing code, I was not sure how my Mac talked to an Arduino and I wanted to have fun while learning that.</p>


                        <p id="description-games7" class="descriptions">Here are some of my sketches. Initially, I got inspired by work that I did for my 3rd year project about breaking the 4th wall in experiencing media and wanted to make people part of the scientific concept that I wanted to communicate. So, the idea of a live quorum sensing exercise came, where I sketched a web app that used live geolocation to have people come together in close areas to produce phenotypes. I thought about how this could be applied to charity events as well.</p>
                        <p id="description-games8" class="descriptions">However, for the London Science Museum there was a constraint of space and I had limited time on hand. So, I moved to something that would really help someone understand what biology is all about: the central dogma. That really helped me understand what ‘DNA codes for protein’ means.</p>
                        <p id="description-games9" class="descriptions">I settled on the central dogma, but combined it with something that’d satisfy all the conditions and constraints. So, I thought that we’d pair up transcription as a Dance Dance revolution game with translation, as an arcade game. The two would communicate between each other and so players would get a chance to see how the 2 processes are connected in bacterial cells.</p>

                        <p id="description-games10" class="descriptions">By the time of the event I learnt about the difficulties in making a product that is used by the end users and does not break. On September 27th, the timing to combine the two games was not ready yet, so their gameplay could not be linked. However, people still tried the games in pairs and I supplemented the experience by engaging more with the audience and explaining the purpose of the installation.</p>
                        <p id="description-games11" class="descriptions">A school teacher asked me to take the installation to a local school in London and I got participants throughout the night to answer a few questions about the potential of the project. I was particularly interested in seeing what their feedback was on learning something about biology, the social component and whether they would take interest in the topic in the near future. </p>
                        <p id="description-games12" class="descriptions">Overall, it was an important project to me, both on the level of ideas about what I would like to do next and skills wise. I became comfortable with building physical things and finding solutions along the way (e.g. in the design of the dance pad). Importantly, I was lucky to go through the iterative process of designing the 2 games, learning about how to accommodate to a user’s needs.</p>
                        <p id="description-games13" class="descriptions">My next plan with Cell Games, as I like to call them, is to work on the quorum sensing sketch and try to break the 4th wall in science communication. Now, I’m still trying to optimise the feedback between the games with Websockets via an Express server, so shoot me an email if you’d like to contribute!</p>

                        <button id="button-games1" type="button" class="btn btn-dark btns">Scope</button>
                        <button id="button-games2" type="button" class="btn btn-dark btns">Process</button>
                        <button id="button-games3" type="button" class="btn btn-dark btns">Moving forward</button>
                    </div>

                    <div id="descriptions-3rd" class="description-container">

                        <p class="descriptions">I think a lot about how we experience and perceive the world around us. So, the concept of breaking the 4th wall in theatre appealed to me and wanted to test it in cognitive science. My 3rd year project focused on using narratives and eye-tracking to see whether eye gaze and storytelling have a common thread to explore.</p>

                        <p class="descriptions">The experiment manipulated the storyteller’s gaze, self-referencing through language and whether the person believe that they were seen or not by the storyteller. I started from theories of self-referencing and direct eye gaze perception and chose to look at the levels of immersion into the narrative and over attention allocation.</p>

                        <p class="descriptions">Results motivated me to still think about how direct eye gaze can contribute in storytelling, especially in designing experiences that leverage what we know about its effects. While further research is needed to assess the exact effects of eye gaze, I am sure that the joint exploration of storytelling, eye gaze and media experiences is a worthwhile one. <a style="text-decoration: none" href="assets/FlorinGheorghiuDissertation.pdf" download>Here</a> you can download the dissertation.</p>

                        <p class="descriptions">Why breaking the 4th wall is important</p>
                        <p class="descriptions">Why breaking the 4th wall is important</p>
                        <p class="descriptions">Why breaking the 4th wall is important</p>

                        <p class="descriptions">Why breaking the 4th wall is important</p>
                        <p class="descriptions">Why breaking the 4th wall is important</p>
                        <p class="descriptions">Why breaking the 4th wall is important</p>

                        <p class="descriptions">Why breaking the 4th wall is important</p>
                        <p class="descriptions">Why breaking the 4th wall is important</p>
                        <p class="descriptions">Why breaking the 4th wall is important</p>

                        <button id="button-3rd1" type="button" class="btn btn-dark btns">Scope</button>
                        <button id="button-3rd2" type="button" class="btn btn-dark btns">Process</button>
                        <button id="button-3rd3" type="button" class="btn btn-dark btns">Moving forward</button>

                    </div>

                    <div id="descriptions-4th" class="description-container">

                        <p id="description-4th1" class="descriptions">I’m currently part of the LAB lab at UCL. I joined to grasp the idea of network interaction in the brain, as it seems like the way forward to understand the brain in real life contexts.</p>
                        <p id="description-4th2" class="descriptions">Before starting to scan, I have been working on using the Google Cloud Speech API to align subtitles from a movie with the audio description for the blind (DVS service). I made a script that uses Voice Activity Detection (VAD) in Python to get wav files of segments of speech, turn them into flac format, send them to Google and get back a json with speech onset timing and the content. Due to pauses in speech, I am working on using text similarity to combine parts of sentences that were split during the VAD.</p>
                        <p id="description-4th3" class="descriptions">Read further to see where I see this going both in terms of programming and the neuroscience.</p>

                        <svg width="7.5%" height="5.5%" viewBox="0 0 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>mark-github</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="mark-github" fill="#000000">
                                    <path d="M8,0 C3.58,0 0,3.58 0,8 C0,11.54 2.29,14.53 5.47,15.59 C5.87,15.66 6.02,15.42 6.02,15.21 C6.02,15.02 6.01,14.39 6.01,13.72 C4,14.09 3.48,13.23 3.32,12.78 C3.23,12.55 2.84,11.84 2.5,11.65 C2.22,11.5 1.82,11.13 2.49,11.12 C3.12,11.11 3.57,11.7 3.72,11.94 C4.44,13.15 5.59,12.81 6.05,12.6 C6.12,12.08 6.33,11.73 6.56,11.53 C4.78,11.33 2.92,10.64 2.92,7.58 C2.92,6.71 3.23,5.99 3.74,5.43 C3.66,5.23 3.38,4.41 3.82,3.31 C3.82,3.31 4.49,3.1 6.02,4.13 C6.66,3.95 7.34,3.86 8.02,3.86 C8.7,3.86 9.38,3.95 10.02,4.13 C11.55,3.09 12.22,3.31 12.22,3.31 C12.66,4.41 12.38,5.23 12.3,5.43 C12.81,5.99 13.12,6.7 13.12,7.58 C13.12,10.65 11.25,11.33 9.47,11.53 C9.76,11.78 10.01,12.26 10.01,13.01 C10.01,14.08 10,14.94 10,15.21 C10,15.42 10.15,15.67 10.55,15.59 C13.71,14.53 16,11.53 16,8 C16,3.58 12.42,0 8,0 L8,0 Z" id="Shape"></path>
                                </g>
                            </g>
                        </svg>

                        <p id="description-4th4" class="descriptions">My goal is to take the brain outside the lab and I saw working on network interaction as a great chance of understanding a higher-level functioning of cognitive processes. At the moment, I am spending time understanding what conclusions we can draw from fMRI data and think about the questions that we can answer through an average signal across the neurons in a voxel.</p>

                        <p id="description-4th5" class="descriptions">A side consequence that became a big part of the project is the decoding of movies. For this, I am using the transcribed audio descriptions for the blind, currently building a LSTM network to train it on Deep Mind’s Kinetics <a style="text-decoration: none" href="https://deepmind.com/research/open-source/open-source-datasets/kinetics/">data</a> and using NLP to mine commentaries about scenes in the movies. This leads to quite a narrow focus of the decoding, specific to the movie.</p>

                        <p class="descriptions">One aspect of it that I am exploring is linking the physiology to the computational aspect more thoroughly.</p>


                        <p class="descriptions">My first aim is to finish off a Python script that allows me to query all the information that we have about a movie at specific time periods. I am planning on approaching the analysis in 2 ways: starting from the brain and starting from the stimulus.</p>

                        <p class="descriptions">From the brain side, if we observe an interaction between networks at specific time points, I want to query my movie about what stimulus triggered that BOLD signal. So, I would get the time period, then use the RNN to classify the action happened in this short clip, extract information from the audio description of the same time, classify objects with Tensorflow’s Inception model and if available get a summary of the scene commentary. Obviously, there are multiple resolutions to play around with and this is something that I am looking forward to once we finish scanning.</p>

                        <p class="descriptions">From the stimulus side, I am interested to see if having the same type of stimulus appear across different time points across the movie would result in the same network interaction in the brain. For this, we would go the other way around, also comparing to what the literature says about stimuli triggering the activation of specific brain regions (e.g. angry faces for the amygdala).</p>

                        <p class="descriptions">The next steps for me, at least, is to integrate this knowledge into the design of interfaces and experiences. While some might think of an evil application to get people hooked on Netflix movies designed to leverage what we know about the brain, they can already do this without all of this data.</p>

                        <p class="descriptions">It also relates to how we can create a super AI, to which I’m thinking that a deep neural network could be trained based on the brain data and the stimuli presented in the movies to produce what time of stimulus produces what kind of activation.</p>

                        <button id="button-4th1" type="button" class="btn btn-dark btns">Scope</button>
                        <button id="button-4th2" type="button" class="btn btn-dark btns">Process</button>
                        <button id="button-4th3" type="button" class="btn btn-dark btns">Moving forward</button>
                    </div>

                    <div id="descriptions-hatch" class="description-container">

                        <p id="description-hatch1" class="descriptions">Hatch London was a hackathon aimed at solving issues coming from the UN. On the day, to my surprise, we were allocated a project to decrease gender discrimination and sexual harassment and assault.</p>
                        <p id="description-hatch2" class="descriptions">I was one of the 2 coders in a team of 5, putting forward the idea of creating an online platform through which agents that implement interventions to reduce sexual harassment can use to assess their effectiveness and improve their implementation strategy. My experience in international development with EPAfrica (see Resume) inspired me to think about how effective these are.</p>
                        <p id="description-hatch3" class="descriptions">Our prototype took data regarding sexual assaults and plotted them on a map. I worked on getting the Geolocation function of the Maps API to work with the UK Police API.</p>

                        <p id="description-hatch4" class="descriptions">Used the pywebrtc library to determine where speech happens in an audio file, outputting wav files, converting them into flac to send to the Google Cloud Speech API and receive a json back with the start time in seconds and the content.</p>
                        <p id="description-hatch5" class="descriptions">Now I'm working on building a Recurrent Neural Network and train a LSTM on Deep Mind's Kinetics data set.</p>

                        <button id="button-hatch1" type="button" class="btn btn-dark btns">Scope</button>
                        <button id="button-hatch2" type="button" class="btn btn-dark btns">Process</button>
                        <button id="button-hatch3" type="button" class="btn btn-dark btns">Moving forward</button>
                    </div>

                </div>

            </div>

        </div>

    </div>



</body>

</html>