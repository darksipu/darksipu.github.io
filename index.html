<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Florin Gheorghiu</title>

    <script src="https://code.jquery.com/jquery-3.2.1.js" integrity="sha256-DZAnKJ/6XZ9si04Hgrsxu/8s717jcIzLy3oi35EouyE=" crossorigin="anonymous"></script>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">


    <link href="style.css" type="text/css" rel="stylesheet">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-111124254-2"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-111124254-2');
    </script>



</head>

<body class="container-fluid">

    <div class="row">

        <div id="side" class="col-sm-2">
            <ul class="navy">

                <li class="navy-link"><a id="about" style="color: black" href="#">ABOUT</a></li>

                <li class="navy-link">PROJECTS

                    <ul class="side-category">

                        <li id="games"><a href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">Gamifying biology</span></a></li>

                        <li id="website"><a href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">Front-end adventures</span></a></li>

                        <li id="4th"><a href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">NeuroMovies</span></a></li>

                        <li id="3rd"><a  href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">Eye gaze & storytelling</span></a></li>

                        <li id="hatch"><a href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">Hatch London</span></a></li>

                        <li id="vr"><a href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                            <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                            <title>chevron-right</title>
                            <desc>Created with Sketch.</desc>
                            <defs></defs>
                            <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                <g id="chevron-right" fill="white">
                                    <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                </g>
                            </g>
                        </svg><span class="heads">Perception of causality</span></a></li>
                    </ul>
                </li>

                <li class="navy-link"><a id="ideas" style="color: black" href="#">IDEAS</a></li>

            </ul>
        </div>

        <div id="tabula" class="col-sm-10">

            <div class="row">

                <div id="pictures" class="col-sm-6">

                    <div id="pictures-intro">
                        <img src="assets/intro1.jpg" style="margin: 3% 0 0 20% !important; display: inline-flex; width: 55%">
                        <img src="assets/igempresentation.jpg" style="margin: 3% 0 0 20% !important; display: inline-flex; width: 55%">
                        <img src="assets/intro2.jpg" style="margin: 3% 0 0 20% !important; display: inline-flex; width: 55%">
                    </div>
                        <!-- photos for the eye gazing project -->

                    <div id="pictures-3rd" class="row">

                            <img src="assets/project-image-gaze1.jpg" id="project-image-1" class="project-image">
                            <img src="assets/project-image-gaze2.jpg" id="project-image-4" class="project-image">

                    </div>

                    <!-- photos for the biology games -->

                    <div id="pictures-games">

                        <div>
                            <iframe class="museumvideo" src="https://player.vimeo.com/video/243147845" width="460" height="280" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
                            <img src="assets/ScienceMuseum1.jpg" id="project-image-5" class="project-image" style="height:10% !important; width: 40% !important; margin-left: 5%">
                            <img src="assets/project-image-sm2.jpg" id="project-image-6" class="project-image" style="height:10% !important; width: 40% !important;">
                            <img src="assets/game.jpg" id="project-image-7" class="project-image" style="height:40% !important; width: 80% !important;">
                        </div>

                        <div>
                            <iframe class="museumvideo" src="https://player.vimeo.com/video/245205558" width="460" height="280" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
                            <img src="assets/padbuilding.jpg" class="project-image" style="height:40% !important; width: 80% !important; margin: 10% 0 0 10%">
                        </div>

                    </div>

                    <!-- photos for the ML -->
                    <div style="margin-bottom: 20%;" id="pictures-4th">
                        <div>
                        <img src="assets/NeuMovies.jpg"class="project-image" height="10%" width="80%">
                        </div>

                        <div>
                            <img src="assets/neumovies1.jpg" class="project-image neu-images" height="10%" width="90%">
                            <img src="assets/neumovies2.jpg" class="project-image neu-images" height="10%" width="90%">
                        </div>
                    </div>

                    <!-- photos for the website -->
                    <div id="pictures-website">

                        <div>
                            <img src="assets/website1.jpg" class="project-image" height="10%" width="80%" style="margin: 3% 0 0 5% !important">
                            <img src="assets/website2.jpg" class="project-image" height="10%" width="80%" style="margin: 3% 0 0 5% !important">
                            <img src="assets/website3.jpg" class="project-image" height="10%" width="80%" style="margin: 3% 0 0 5% !important">
                        </div>

                        <img src="assets/UserJourneyoverview.png" class="project-image" height="10%" width="80%" style="margin: 20% 0 30% 15% !important">
                        <img src="assets/UserJourney-Part1.png" class="project-image" height="10%" width="80%" style="margin: 10% 0 10% 10% !important">
                        <img src="assets/barchitecture.png" class="project-image" height="10%" width="80%" style="margin: 3% 0 0 10% !important">
                    </div>

                    <!-- photos for Hatch-->
                    <div id="pictures-hatch">
                        <img src="assets/hatch.jpg" id="project-image-14" class="project-image" height="10%" width="80%" style="margin: 20% 0 20% 10%">
                    </div>

                    <div id="pictures-harvard">
                        <img src="assets/Poster.png" class="project-image" height="10%" width="100%" style="margin: 20% 0 80% 10%">
                    </div>

                    <!-- Section for the ideas-->

                    <div style="margin-top: 20%; margin-bottom: 50%" id="content-ideas">

                        <!-- Fractals-->
                        <div>
                            <p class="descriptions">Edmund Burke was one of the first to philosophically compare the aesthetic characteristics of the sublime and beauty. The question that I found myself asking was how these two can appear in everyday life.</p>
                            <p class="descriptions">Currently, I am in the research phase of making fractal glasses. As in the fractal pattern that I made above, how would some glasses that figure out what we’ve found to be beautiful turn that into a recursive pattern? According to Burke, minute features are the aesthetics of beauty. But at the same time, infinity is associated with the sublime, a feeling of great terror.</p>
                            <p class="descriptions">At the moment, I’m trying to see what’s possible with applying fractals to objects abstracted from an image. Maybe the next steps are looking into VR or AR. But hey, we may be able to even excite people about fractals again.</p>
                        </div>

                        <!-- The collab app-->
                        <div>
                            <p class="descriptions">When a group of friends sees a street performance or goes to a gallery, everyone takes out their own phones and starts recording the moments separately. By doing this, we put a barrier between us and the world, maybe knowing that we’ll later be able to come back to it. </p>
                            <p class="descriptions">But if only one person in the group had that ability, the others would actually have to share their perspective of what they find cool or interesting about the scene if they want the ‘recorder' to capture the moment. If you extend the limitations to how much you can record, people may become creative in how they choose to experience a moment.</p>
                            <p class="descriptions">At the moment I’m thinking and reading about what tricks can be employed by technology to make us put more effort into the present moment and not think about the future.</p>
                        </div>

<!--                        &lt;!&ndash; Evolution of words&ndash;&gt;
                        <div>
                            <p class="descriptions">Biological evolution is cool, but what happens to concepts - as part of my Masters, I am learning how web scraping works, so I am curious how our concepts of things work - when an AI will use certain words, will that machine use Psychology to refer to something that people study to ‘read your mind’, as most people would put it? Who knows, maybe we can evolve new words, some of which we haven’t even thought that we would need. Words that we need for experiences - you would try to say something, but maybe there’s no word in English for it. Or in Portuguese, nor in Japanese. So how about we make a word based on natural statistics of language?</p>
                        </div>-->

                    </div>

                </div>

                <!-- The column with the text in -->
                <div id="descriptions" class="col-sm-6">

                    <div id="introbit">
                        <p style="font-size: 3vw" class="intro">Florin Gheorghiu</p>

                        <p style="padding-top: 1%" class="intro">London,UK</p>

                        <p class="intro"><b>Officially</b>, my time is spent reading about neurons & AI, designing experiments and doing multivariate statistics at UCL @ the LAB lab.</p>

                        <p class="intro"><b>Unofficially</b>, I code games and websites, learn about synthetic biology, play with Arduinos and think about how technology can completely change the way we interact with the world around us. I also like speaking in public and I'm a geek when it comes to Japan.</p>

                        <p class="intro">Here's my <a style="text-decoration: none" href="assets/Florin%20Gheorghiu%20-%20CV.pdf" download>CV</a> for education, work experience and international development projects.</p>

                        <div id="contacts">
                            <a href="mailto:florin.gheorghiu24@gmail.com" target="_top"><svg width="7.5%" height="7.5%" viewBox="0 0 14 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                                <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                                <title>mail</title>
                                <desc>Created with Sketch.</desc>
                                <defs></defs>
                                <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                    <g id="mail" fill="#000000">
                                        <path d="M0,4 L0,12 C0,12.55 0.45,13 1,13 L13,13 C13.55,13 14,12.55 14,12 L14,4 C14,3.45 13.55,3 13,3 L1,3 C0.45,3 0,3.45 0,4 L0,4 Z M13,4 L7,9 L1,4 L13,4 L13,4 Z M1,5.5 L5,8.5 L1,11.5 L1,5.5 L1,5.5 Z M2,12 L5.5,9 L7,10.5 L8.5,9 L12,12 L2,12 L2,12 Z M13,11.5 L9,8.5 L13,5.5 L13,11.5 L13,11.5 Z" id="Shape"></path>
                                    </g>
                                </g>
                            </svg></a>
                            <a href="https://github.com/darksipu"><svg width="7.5%" height="5.5%" viewBox="0 0 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                                <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                                <title>mark-github</title>
                                <desc>Created with Sketch.</desc>
                                <defs></defs>
                                <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                    <g id="mark-github" fill="#000000">
                                        <path d="M8,0 C3.58,0 0,3.58 0,8 C0,11.54 2.29,14.53 5.47,15.59 C5.87,15.66 6.02,15.42 6.02,15.21 C6.02,15.02 6.01,14.39 6.01,13.72 C4,14.09 3.48,13.23 3.32,12.78 C3.23,12.55 2.84,11.84 2.5,11.65 C2.22,11.5 1.82,11.13 2.49,11.12 C3.12,11.11 3.57,11.7 3.72,11.94 C4.44,13.15 5.59,12.81 6.05,12.6 C6.12,12.08 6.33,11.73 6.56,11.53 C4.78,11.33 2.92,10.64 2.92,7.58 C2.92,6.71 3.23,5.99 3.74,5.43 C3.66,5.23 3.38,4.41 3.82,3.31 C3.82,3.31 4.49,3.1 6.02,4.13 C6.66,3.95 7.34,3.86 8.02,3.86 C8.7,3.86 9.38,3.95 10.02,4.13 C11.55,3.09 12.22,3.31 12.22,3.31 C12.66,4.41 12.38,5.23 12.3,5.43 C12.81,5.99 13.12,6.7 13.12,7.58 C13.12,10.65 11.25,11.33 9.47,11.53 C9.76,11.78 10.01,12.26 10.01,13.01 C10.01,14.08 10,14.94 10,15.21 C10,15.42 10.15,15.67 10.55,15.59 C13.71,14.53 16,11.53 16,8 C16,3.58 12.42,0 8,0 L8,0 Z" id="Shape"></path>
                                    </g>
                                </g>
                            </svg></a>
                        </div>

                    </div>

                    <div id="descriptions-website" class="description-container">

                        <div>
                            <button id="button-website1" type="button" class="btn btn-dark btns">Overview</button>
                            <button id="button-website2" type="button" class="btn btn-dark btns">Why</button>
                            <button id="button-website3" type="button" class="btn btn-dark btns">How</button>
                            <button id="button-website4" type="button" class="btn btn-dark btns">Moving forward</button>
                        </div>

                        <div>
                            <p class="descriptions">Part of my iGEM responsibilities was designing the UX and coding the team’s <a style="text-decoration: none" href="http://2017.igem.org/Team:UCL">website</a>. As my first long-term major coding project, I learnt and practiced a lot of HTML, CSS and Javascript. Unfortunately, the vanilla in web development, but looking forward to playing around with React soon. </p>
                            <p class="descriptions">Throughout the project, it was important to find easy solutions to saying something clearly and making it easy to consume the information on our wiki. As a newbie, I didn’t use any professional software for the UX, but went for something quick and practical to get everyone in the team an idea of what content needs producing (i.e. text and diagrams).</p>
                            <p class="descriptions bottom-line">Special thanks to Anima Sutradhar for the diagrams and artwork, and together with Rabia T Khan and Jaime Domingues from Benevolent AI for help, advice and suggestions on the UX.</p>
                        </div>

                        <div>
                            <p class="descriptions">The whole website took around 3 months from the first ideas, to wireframes, initial designs, agreeing on a structure and theme with the team, creating content, refining, testing UX and dealing with iGEM’s ridiculous rules about website hosting.</p>

                            <p class="descriptions">From the start, I wanted to build a website that wasn’t just pretty, but one that satisfied the purpose of our project: serve as a wiki for people to build upon it, access information and have a pleasant reading experience. </p>

                            <p class="descriptions bottom-line">Also, given the limitations with iGEM website hosting, I decided to use vanilla HTML, CSS and JavaScript. However, along the way, the most interesting part was the challenge of designing good UX.</p>
                        </div>

                        <div>
                            <p class="descriptions">Here are some of the wireframes for the home and project description pages. It was a lengthy process of design, going back and forth between the person who was designing the diagrams and visuals, what the die-hard biologists wanted to put on the first page and myself. However, I felt like it helped me come up with alternative solutions and understand why some parts of the project were important.</p>

                            <p class="descriptions bottom-line">I did not use any professional tools for UX, relying on a way to prototype quickly and practically, while getting everyone in the team on the same page in terms of what content needs to be produced.</p>
                        </div>

                        <div>
                             <p class="descriptions">My first web development gig  helped me build the necessary tools to deploy a website, undertake a lengthy process with specific deliverables and work towards satisfying my ‘clients’ (as I like to call the iGEM judges and my team mates). </p>

                             <p class="descriptions bottom-line">The skills proved useful, as recently I used them in a hackathon (see <i>Hatch London</i>) to build a prototype for an online platform.</p>
                        </div>


                    </div>

                    <div id="descriptions-games" class="description-container">

                        <div>
                            <button id="button-games1" type="button" class="btn btn-dark btns">Overview</button>
                            <button id="button-games2" type="button" class="btn btn-dark btns">Why</button>
                            <button id="button-games3" type="button" class="btn btn-dark btns">How</button>
                            <button id="button-games4" type="button" class="btn btn-dark btns">Moving forward</button>
                        </div>

                        <div>
                            <p class="descriptions">During my iGEM project, transforming monotonous science communication into an exciting story about synthetic biology seemed like a fruitful challenge.</p>
                            <p class="descriptions">I had 1 month to build an installation that would impress the <a style="text-decoration: none" href="https://www.sciencemuseum.org.uk/see-and-do/lates">London Science Museum Lates</a> team enough to be part of their evening. After a few iterations, gamifying the central dogma of molecular biology seemed like a great idea to learn some new skills and test whether games can be used to tell stories in science. The result was well received and now the project is in a new design cycle to improve on the feedback received.</p>
                            <p class="descriptions bottom-line"><a style="text-decoration: none" href="https://github.com/darksipu/cell-games">Here</a>’s the code on GitHub to play yourself and build on top of it (details there).</p>
                        </div>

                        <div>
                            <p class="descriptions">The aim was to test whether through an installation we can give an intuitive understanding of a molecular biology concept, get people excited and transform the experience of gaming from an isolated bedroom nerd to a social game that you’d play around the Christmas table. My hypothesis was that such a combination would be well received and replaced the usual experimental controls with user testing.</p>
                            <p class="descriptions">But arcade games are still so fun. So, the goal was to design something that has the fun of traditional video games, adds a social component and is a useful gateway into synthetic biology.</p>
                            <p class="descriptions bottom-line">Also, I wanted to couple my newly learnt molecular biology with something that had wanted to do for a while: hardware.</p>
                        </div>

                        <div>
                            <p class="descriptions">Initially, inspiration came from my 3rd year thesis: breaking the 4th wall in media experience. I decided that the game should make users part of the mechanisms involved in the scientific concept explained. So, the first idea was of a live <a style="text-decoration: none;" href="https://en.wikipedia.org/wiki/Quorum_sensing">quorum sensing</a> exercise: through a web app that uses geolocation, people can use their phones to move around London, come together and produce phenotypes, similarly to how bacteria do it. The phenotypes could be shown on a map, or using augmented reality to place virtual objects around London.</p>
                            <p class="descriptions">However, there was a constraint of space at the London Science Museum, so the idea shifted to using colour adaptation for people to figure out the pairing rules of DNA. After testing the feasibility and with one month on hand, the idea pivoted completely to gamifying the central dogma of molecular biology. This way, I could finish the actual installation and explain a fundamental idea in molecular biology, which if understood, would also help a user understand what the latest article about bacteria and their DNA actually means.</p>
                            <p class="descriptions bottom-line">The game paired up transcription with a Dance Dance Revolution-like game and translation with a classic arcade game. The fun was there and so was the part about illustrating biological principles. To add the last component about making players interact, the two games had to be connected: the results from the translation game would feed into the transcription one, with participants having to see what each other is doing.</p>
                        </div>

                        <div>
                            <p class="descriptions">On September 27th, the two games were ready, but making one feed into another was not ready yet, even after a week of user testing. The solution was to have people play in pairs, supplementing the experience by engaging with the players before and after the game to explain the connection between translation and transcription.</p>
                            <p class="descriptions">A school teacher invited us to take the installation to a local school in London and I got user feedback throughout the night about gameplay and the potential of gamification in science communication. My interest was in particularly seeing what their feedback was on learning something about biology, the social component and whether they would take interest in the topic in the near future. </p>
                            <p class="descriptions bottom-line">My next plan with Cell Games is to first implement the feedback from the event and connect the 2 games via an express server, so shoot me an email if you’d like to collaborate! In the near future, I’d want to explore the live quorum sensing exercise and start prototyping.</p>
                        </div>

                    </div>

                    <div id="descriptions-3rd" class="description-container">

                        <div>
                            <button id="button-3rd1" type="button" class="btn btn-dark btns">Overview</button>
                            <button id="button-3rd2" type="button" class="btn btn-dark btns">Why</button>
                            <button id="button-3rd3" type="button" class="btn btn-dark btns">How</button>
                            <button id="button-3rd4" type="button" class="btn btn-dark btns">Moving forward</button>
                        </div>

                        <div>
                            <p class="descriptions">The concept of breaking the 4th wall in theatre appealed to me, so <a style="text-decoration: none" href="assets/FlorinGheorghiuDissertation.pdf" download>my 3rd year</a> project's focus was on using narratives and eye-tracking to see whether eye gaze and storytelling have a common thread to explore.</p>

                            <p class="descriptions">The experiment looked at the effects of the the storyteller’s gaze, self-referencing through language and whether the person believed that they were seen or not by the storyteller on the levels of immersion into the narrative and overt attention allocation.</p>

                            <p class="descriptions bottom-line">Gaze direction and the belief of being seen turned out to influence both measurements. Now, I plan to continue this exploration in the design of storytelling experiences that leverage these effects. <a style="text-decoration: none" href="assets/FlorinGheorghiuDissertation.pdf" download>Here</a> you can download the dissertation.</p>
                        </div>

                        <div>
                            <p class="descriptions">Both technology and storytelling immerse us into their microworlds. To design  and implement technology that helps us be more present into the moment, exploring factors related to storytelling that may have a biological underlying effect seemed worthwhile.</p>
                            <p class="descriptions bottom-line">When researching, eye gaze and particularly direct eye gaze came up again and again with ‘special’ effects on cognition. Looking through studies that measured EDA, heart rate, EEG and behavioural effects, it became clear that it’s a factor that can influence storytelling. Combined with theories of self-referencing, that suggest that memory is augmented when the individual processes stimuli in relation to the self, I designed the task to manipulate all of these factors, while considering how the 4th wall of cognitive science can be broken.</p>
                        </div>

                        <div>
                            <p class="descriptions">Throughout the process, my project required me to improve on my acting skills to record the stimuli, learn about recording with multiple cameras and the necessary lightning and to learn how eye-tracking works. </p>
                            <p class="descriptions bottom-line">The experimental manipulations involved telling the story in the second and 3rd person, to change the level of self-referencing ('You wake up in the car' vs 'James wakes up in the car'). To control the person's belief of being seen or not, participants were tricked to believe that through the computer's camera, they were recorded to be later seen by the actor or just for set-up reasons (in fact they were not recorded).</p>
                        </div>

                        <div>
                            <p class="descriptions">The end aim with this line of ideas was to see whether the effects of a storyteller's eye gaze can be integrated into the design of stories. The next step is to test memory effects of direct eye-gaze and combine this with machine-learning approaches that by using generative adversarial networks, one can produce media experiences that enhance self-referential processing through direct eye-gaze effects.</p>
                            <p class="descriptions bottom-line">On a similar note, I do think about how interactions with future general AI will happen, particularly whether we will believe that we are being seen or not.</p>
                        </div>


                    </div>

                    <div id="descriptions-4th" class="description-container">

                        <div>
                            <button id="button-4th1" type="button" class="btn btn-dark btns">Overview</button>
                            <button id="button-4th2" type="button" class="btn btn-dark btns">Why</button>
                            <button id="button-4th3" type="button" class="btn btn-dark btns">How</button>
                            <button id="button-4th4" type="button" class="btn btn-dark btns">Moving forward</button>
                        </div>

                        <div>
                            <p id="description-4th1" class="descriptions">I joined the LAB lab at UCL to grasp the idea of network interaction in the brain, as it seems like the way forward to understand the brain in real life contexts. My Masters research project involves scanning people watching full length movies, to obtain data on how the brain processes information that resembles real life (e.g. natural scenes, natural language).</p>
                            <p id="description-4th2" class="descriptions">Before starting the fMRI scans, I have been working on using the Google Cloud Speech API to align subtitles from a movie with the audio description for the blind (DVS service). I made a script that uses Voice Activity Detection (VAD) in Python to get wav files of segments of speech, turn them into flac format, send them to Google and get back a json with speech onset timing and the content. Due to pauses in speech, I am working on using text similarity to combine parts of sentences that were split during the VAD.</p>
                            <p id="description-4th3" class="descriptions">Read further to see where I see this going both in terms of programming and the neuroscience.</p>
                            <div class="githubs">
                           <a href="https://github.com/jskipper/movie"><svg width="10%" height="10%" viewBox="0 0 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                                <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                                <title>mark-github</title>
                                <desc>Created with Sketch.</desc>
                                <defs></defs>
                                <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                    <g id="mark-github" fill="#000000">
                                        <path d="M8,0 C3.58,0 0,3.58 0,8 C0,11.54 2.29,14.53 5.47,15.59 C5.87,15.66 6.02,15.42 6.02,15.21 C6.02,15.02 6.01,14.39 6.01,13.72 C4,14.09 3.48,13.23 3.32,12.78 C3.23,12.55 2.84,11.84 2.5,11.65 C2.22,11.5 1.82,11.13 2.49,11.12 C3.12,11.11 3.57,11.7 3.72,11.94 C4.44,13.15 5.59,12.81 6.05,12.6 C6.12,12.08 6.33,11.73 6.56,11.53 C4.78,11.33 2.92,10.64 2.92,7.58 C2.92,6.71 3.23,5.99 3.74,5.43 C3.66,5.23 3.38,4.41 3.82,3.31 C3.82,3.31 4.49,3.1 6.02,4.13 C6.66,3.95 7.34,3.86 8.02,3.86 C8.7,3.86 9.38,3.95 10.02,4.13 C11.55,3.09 12.22,3.31 12.22,3.31 C12.66,4.41 12.38,5.23 12.3,5.43 C12.81,5.99 13.12,6.7 13.12,7.58 C13.12,10.65 11.25,11.33 9.47,11.53 C9.76,11.78 10.01,12.26 10.01,13.01 C10.01,14.08 10,14.94 10,15.21 C10,15.42 10.15,15.67 10.55,15.59 C13.71,14.53 16,11.53 16,8 C16,3.58 12.42,0 8,0 L8,0 Z" id="Shape"></path>
                                    </g>
                                </g>
                            </svg></a>
                        </div>

                        </div>

                        <div>
                            <p class="descriptions">My goal is to take the brain outside the lab and I saw working on network interaction as a great chance of understanding the higher-level functioning of cognitive processes.</p>
                            <p class="descriptions bottom-line">Decoding the movies has become a big part of the project. For this, I am using the transcribed audio descriptions for the blind, currently building a LSTM network to train it on Deep Mind’s Kinetics <a style="text-decoration: none" href="https://deepmind.com/research/open-source/open-source-datasets/kinetics/">data</a> and using NLP to mine commentaries about scenes in the movies.</p>
                        </div>

                        <div>
                            <p class="descriptions">My first aim is to finish off a Python script that allows me to query all the information that we have about a movie at specific time periods. I am planning on approaching the analysis in 2 ways: starting from the brain and starting from the stimulus.</p>
                            <p class="descriptions">From the brain side, if we observe an interaction between networks at specific time points, I want to query my movie about what stimulus triggered that BOLD signal. So, I would get the time period, then use the RNN to classify the action happened in this short clip, extract information from the audio description of the same time, classify objects with Tensorflow’s Inception model and if available get a summary of the scene commentary. There are multiple resolutions to play around with and this is something that I am looking forward to, once we finish scanning.</p>
                            <p class="descriptions bottom-line">From the stimulus side, I am interested to see if having the same type of stimulus appear at different time points across the movie would result in the same network interaction in the brain. For this, we would go the other way around, also comparing to what the literature says about stimuli triggering the activation of specific brain regions (e.g. angry faces for the amygdala).</p>

                        </div>

                        <div>
                            <p class="descriptions">The next steps for me is to integrate this knowledge into the design of interfaces and experiences. While some might think of an evil application to get people hooked on Netflix movies designed to leverage what we know about the brain, they can already do this without all of this data.</p>
                            <p class="descriptions bottom-line">It also relates to how we can create a super AI, to which I’m thinking that a deep neural network could be trained based on the brain data and the stimuli presented in the movies to produce what time of stimulus produces what kind of activation.</p>
                        </div>


                    </div>

                    <div id="descriptions-hatch" class="description-container">

                        <p id="description-hatch1" class="descriptions"><a href="https://shecancode.io/attend-events/hatch-london">Hatch London</a> was a 36h hackathon aimed at working on UN’s sustainable development goals. On the day we were given the topic of developing a solution to sexual harassment, assault or gender discrimination.</p>
                        <p id="description-hatch2" class="descriptions">My idea was of an online platform where one can assess the effectiveness of interventions aimed at reducing sexual harassment and gender discrimination. The team of five (I was one of the coders) embraced it and we set to use a data-driven approach that would collect via APIs and web scraping the social media posts, police data and anonymous reports to plot in an area a more objective picture of the state of the problem. Then, governments, companies and charities that have implemented interventions to reduce the problem can see whether they have had impact. My experience in international development with EPAfrica inspired me to think about the sustainability of interventions and assessing their effectiveness.</p>
                        <p id="description-hatch3" class="descriptions">Our prototype took data on sexual assaults in a given area from the UK Police API and plotted them on a map. My team mate took care of the heat maps and visualisation, while I worked on getting the geolocation function of the Google Maps API to produce 3 other coordinates to send to the Police API and some of the front end.</p>

                        <div class="githubs">
                            <a href="https://github.com/wonjoonSeol/hatch-template-project"><svg width="15%" height="10%" viewBox="0 0 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                                <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                                <title>mark-github</title>
                                <desc>Created with Sketch.</desc>
                                <defs></defs>
                                <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                    <g id="mark-github" fill="#000000">
                                        <path d="M8,0 C3.58,0 0,3.58 0,8 C0,11.54 2.29,14.53 5.47,15.59 C5.87,15.66 6.02,15.42 6.02,15.21 C6.02,15.02 6.01,14.39 6.01,13.72 C4,14.09 3.48,13.23 3.32,12.78 C3.23,12.55 2.84,11.84 2.5,11.65 C2.22,11.5 1.82,11.13 2.49,11.12 C3.12,11.11 3.57,11.7 3.72,11.94 C4.44,13.15 5.59,12.81 6.05,12.6 C6.12,12.08 6.33,11.73 6.56,11.53 C4.78,11.33 2.92,10.64 2.92,7.58 C2.92,6.71 3.23,5.99 3.74,5.43 C3.66,5.23 3.38,4.41 3.82,3.31 C3.82,3.31 4.49,3.1 6.02,4.13 C6.66,3.95 7.34,3.86 8.02,3.86 C8.7,3.86 9.38,3.95 10.02,4.13 C11.55,3.09 12.22,3.31 12.22,3.31 C12.66,4.41 12.38,5.23 12.3,5.43 C12.81,5.99 13.12,6.7 13.12,7.58 C13.12,10.65 11.25,11.33 9.47,11.53 C9.76,11.78 10.01,12.26 10.01,13.01 C10.01,14.08 10,14.94 10,15.21 C10,15.42 10.15,15.67 10.55,15.59 C13.71,14.53 16,11.53 16,8 C16,3.58 12.42,0 8,0 L8,0 Z" id="Shape"></path>
                                    </g>
                                </g>
                            </svg></a>
                        </div>

                    </div>

                    <div id="descriptions-harvard" class="description-container">

                        <p class="descriptions">Poster from my summer gig in the Carey Lab at the Harvard Lab for Developmental studies.</p>
                        <p class="descriptions">The study looked at whether infants have a perception of causality and whether they can distinguish between different types of causal events in their environments. The interesting question is whether the perception of causality is something learned during lifetime or an innate ability that evolved for our advantage. </p>
                        <p class="descriptions">I worked on running participants, programming the psychophysics experiments in Python and contributed to building in Python a new gaze habituation program for the lab, as the previous one was running an ancient set-up.</p>
                    </div>



                    <div id="menu-ideas" class="description-container">

                        <ul style="max-width: 40%" class="side-category">

                            <li><a id='fractals' href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                                <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                                <title>chevron-right</title>
                                <desc>Created with Sketch.</desc>
                                <defs></defs>
                                <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                    <g id="chevron-right" fill="black">
                                        <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                    </g>
                                </g>
                            </svg><span class="heads">Fractal glasses</span></a></li>

                            <li><a id='app' href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                                    <!-- Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch -->
                                    <title>chevron-right</title>
                                    <desc>Created with Sketch.</desc>
                                    <defs></defs>
                                    <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                        <g id="chevron-right" fill="black">
                                            <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                        </g>
                                    </g>
                                </svg><span class="heads"> No more filming</span></a></li>
<!--

                            <li><a id='words' href="#" class="project-name"><svg width="7%" height="15%" viewBox="0 0 8 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                                    &lt;!&ndash; Generator: Sketch 40.3 (33839) - http://www.bohemiancoding.com/sketch &ndash;&gt;
                                    <title>chevron-right</title>
                                    <desc>Created with Sketch.</desc>
                                    <defs></defs>
                                    <g id="Octicons" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                                        <g id="chevron-right" fill="black">
                                            <polygon id="Shape" points="7.5 8 2.5 13 1 11.5 4.75 8 1 4.5 2.5 3"></polygon>
                                        </g>
                                    </g>
                                </svg><span class="heads">Word evolution</span></a></li>
-->

                        </ul>
                    </div>

                </div>

            </div>

        </div>

    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js" integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn" crossorigin="anonymous"></script>
    <script language="javascript" type="text/javascript" src="actions.js"></script>
</body>

</html>
